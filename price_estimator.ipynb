{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCG_tNZwkzTj",
        "outputId": "78fe99a3-a987-4132-974c-61b962097314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.0/1.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSn2P84tk7qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3c6c78-ea69-4346-9379-d47f65bfa2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 15428\n",
            "Estimate price (USD): 0.23142\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "# Here is a unit test\n",
        "#enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "#assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
        "\n",
        "#=======================================================================\n",
        "model = 'gpt-4o' # the model to test\n",
        "price = 0.015  # the cost per 1000 tokens\n",
        "\n",
        "'''\n",
        "Check here for the latest price: https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)\n",
        "\n",
        "Please note that cost of the prompt (input) and the answer (output) from LLM is different, but I did not disguish the\n",
        "two cases in this script.\n",
        "If your task is a classification task, and the answer is just one or two words, you can use the input price.\n",
        "If your task is a text generation task, you may need to use the output price or the mean of input and output prices.\n",
        "\n",
        "To estimate the maximum value, use the output price.\n",
        "'''\n",
        "\n",
        "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
        "enc = tiktoken.encoding_for_model(model)\n",
        "\n",
        "# Read the prompt file\n",
        "#prompt_file = '../Blood-Pressure-Study/Codes/yuting/LLM/prompt/p_0326.txt'\n",
        "#with open(prompt_file) as f:\n",
        "    #prompt_text = f.read()\n",
        "\n",
        "prompt_text = \"find demographic data in above text.\"\n",
        "\n",
        "# Read data\n",
        "import pandas as pd\n",
        "#df = pd.read_csv('/labs/sarkerlab/yguo262/solr-9.5.0/bp_pmc_html_text_output_split_output.clean.csv', dtype=str)\n",
        "\n",
        "f = \"/content/12_f2b8d564818147fb84d274f35ef02f58.13.22Pre-ReadingNEJMMaronSuddenDeathReview2003_output_32bc8f647fe149f4a7c6350eb885b879.txt\"\n",
        "with open(f) as f:\n",
        "  lines = f.readlines()\n",
        "# Tokenization\n",
        "all_tokens = []\n",
        "#for i, text in enumerate(df['text_txt_en']):\n",
        "for i, text in enumerate(lines):\n",
        "    input_text = text + '\\n' + prompt_text\n",
        "    tokens = enc.encode(input_text)\n",
        "    all_tokens += tokens\n",
        "    #print(f'{i}\\t{len(tokens)}')\n",
        "\n",
        "#all_tokens = 4800\n",
        "\n",
        "print('Total tokens:', len(all_tokens))\n",
        "print('Estimate price (USD):', float(len(all_tokens) * price/1000))"
      ]
    }
  ]
}